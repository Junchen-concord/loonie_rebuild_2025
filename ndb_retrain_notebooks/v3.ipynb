{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import pyodbc\n",
        "import urllib\n",
        "import joblib\n",
        "import json\n",
        "from sqlalchemy import create_engine \n",
        "from datetime import datetime, date\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1742564746183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x = pd.read_csv('Users/andrew/Loonie_V3_ND/traininginputdata.csv')\n",
        "# y = pd.read_csv('Users/andrew/Loonie_V3_ND/trainingoutputdata.csv')\n",
        "\n",
        "x = pd.read_csv('traininginputdata.csv')\n",
        "y = pd.read_csv('trainingoutputdata.csv')\n",
        "x"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "      ScoredAppID  CustomerID  frequency  avg_amountReq  med_amountReq  \\\n0             295       233.0        100     475.617978          500.0   \n1             351       281.0         10     375.000000          400.0   \n2             352       282.0          4     616.666667          600.0   \n3             366       295.0          5     510.000000          500.0   \n4             368       296.0          2     675.000000          675.0   \n...           ...         ...        ...            ...            ...   \n2109        25845     15881.0         26    1242.307692         1250.0   \n2110        25906      6726.0          2     500.000000          500.0   \n2111        25988     15977.0          3    1250.000000         1250.0   \n2112        25999     15985.0         20     381.578947          400.0   \n2113         5494      3364.0          7     692.857143          500.0   \n\n      std_amountReq  Yeardiff_max  Yeardiff_min  Yeardiff_mean  \\\n0        343.090881             3             1       2.340000   \n1        116.069902             3             1       2.200000   \n2        125.830574             1             1       1.000000   \n3        159.687194             2             1       1.200000   \n4        106.066017             7             2       4.500000   \n...             ...           ...           ...            ...   \n2109     283.792991             1             0       0.192308   \n2110       0.000000             1             1       1.000000   \n2111     250.000000             1             1       1.000000   \n2112      98.897430             1             0       0.700000   \n2113     501.189062             3             1       1.857143   \n\n      Yeardiff_median  Monthdiff_max  Monthdiff_min  Monthdiff_mean  \\\n0                 2.0              7             -4        1.400000   \n1                 2.0              7             -4        2.300000   \n2                 1.0              4              3        3.500000   \n3                 1.0              6             -4        2.800000   \n4                 4.5              5              1        3.000000   \n...               ...            ...            ...             ...   \n2109              0.0              6             -4        1.500000   \n2110              1.0              2              0        1.000000   \n2111              1.0              1             -4       -1.333333   \n2112              1.0              7             -3        3.850000   \n2113              2.0              6             -4        1.714286   \n\n      Monthdiff_median  Weekdiff_max  Weekdiff_min  Weekdiff_mean  \\\n0                  0.0            32           -19       5.980000   \n1                  4.0            32           -18      11.000000   \n2                  3.5            17            15      15.750000   \n3                  4.0            28           -15      13.200000   \n4                  3.0            21             3      12.000000   \n...                ...           ...           ...            ...   \n2109               1.0            26           -17       6.230769   \n2110               1.0             9            -2       3.500000   \n2111              -1.0             6           -18      -5.000000   \n2112               5.0            32           -12      17.100000   \n2113               4.0            25           -18       8.285714   \n\n      Weekdiff_median  Daydiff_max  Daydiff_min  Daydiff_mean  Daydiff_median  \\\n0                 2.0         1142          499    893.280000           926.0   \n1                18.0         1247          590    878.300000           925.0   \n2                15.5          485          469    473.750000           470.5   \n3                18.0          622          468    529.000000           505.0   \n4                12.0         2577          876   1726.500000          1726.5   \n...               ...          ...          ...           ...             ...   \n2109              4.0          321           19    112.730769            96.5   \n2110              3.5          425          351    388.000000           388.0   \n2111             -3.0          405          236    327.333333           341.0   \n2112             23.0          544           26    373.950000           480.0   \n2113             19.0          962          494    732.857143           737.0   \n\n      have_valid_phone  times_valid_phone  total_phone_enter  \\\n0                    1                100                100   \n1                    1                 10                 10   \n2                    1                  4                  4   \n3                    1                  5                  5   \n4                    1                  2                  2   \n...                ...                ...                ...   \n2109                 1                 26                 26   \n2110                 1                  2                  2   \n2111                 1                  3                  3   \n2112                 1                 20                 20   \n2113                 1                  7                  7   \n\n      correct_phone_rate  num_unique_valid_phone  Loanspaidoff_count  \\\n0                    1.0                       5                   0   \n1                    1.0                       1                   0   \n2                    1.0                       1                   0   \n3                    1.0                       1                   0   \n4                    1.0                       1                   0   \n...                  ...                     ...                 ...   \n2109                 1.0                       1                   3   \n2110                 1.0                       1                   0   \n2111                 1.0                       1                   0   \n2112                 1.0                       1                   5   \n2113                 1.0                       2                   0   \n\n      Incollection_count  Loanspaidoff_count_in30days  \\\n0                      0                            0   \n1                      4                            0   \n2                      0                            0   \n3                      0                            0   \n4                      0                            0   \n...                  ...                          ...   \n2109                   0                            0   \n2110                   0                            0   \n2111                   0                            0   \n2112                   0                            0   \n2113                   1                            0   \n\n      Incollection_count_in30days  Loanspaidoff_rate  Fraudster_app_count  \\\n0                               0           0.000000                    0   \n1                               0           0.000000                    0   \n2                               0           0.000000                    0   \n3                               0           0.000000                    0   \n4                               0           0.000000                    0   \n...                           ...                ...                  ...   \n2109                            0           0.999997                    0   \n2110                            0           0.000000                    0   \n2111                            0           0.000000                    0   \n2112                            0           0.999998                    0   \n2113                            0           0.000000                    0   \n\n      Fraudster_lender_count  Fraudster_app_count_in30days  \\\n0                          0                             0   \n1                          0                             0   \n2                          0                             0   \n3                          0                             0   \n4                          0                             0   \n...                      ...                           ...   \n2109                       0                             0   \n2110                       0                             0   \n2111                       0                             0   \n2112                       0                             0   \n2113                       0                             0   \n\n      Fraudster_lender_count_in30days  Refused_count  Refused_rate  \\\n0                                   0             62      0.659574   \n1                                   0              2      0.222222   \n2                                   0              3      0.750000   \n3                                   0              5      1.000000   \n4                                   0              1      0.500000   \n...                               ...            ...           ...   \n2109                                0              2      0.090909   \n2110                                0              2      1.000000   \n2111                                0              2      0.666667   \n2112                                0             10      0.500000   \n2113                                0              2      0.333333   \n\n      Refused_count_within30days  Refused_rate_within30days  \\\n0                              2                   1.000000   \n1                              0                   0.000000   \n2                              3                   0.750000   \n3                              2                   1.000000   \n4                              1                   1.000000   \n...                          ...                        ...   \n2109                           1                   0.111111   \n2110                           1                   1.000000   \n2111                           0                   0.000000   \n2112                           0                   0.000000   \n2113                           0                   0.000000   \n\n      Refused_count_before30days  Refused_rate_before30days  FPDAA  \\\n0                             60                   0.652174    0.0   \n1                              2                   0.285714    0.0   \n2                              0                   0.000000    0.0   \n3                              3                   1.000000    0.0   \n4                              0                   0.000000    0.0   \n...                          ...                        ...    ...   \n2109                           1                   0.076923    0.0   \n2110                           1                   1.000000    0.0   \n2111                           2                   1.000000    0.0   \n2112                          10                   0.526316    0.0   \n2113                           2                   0.400000    0.0   \n\n          ApplicationDate  AppID   Age  \n0     2023-05-03 16:53:28    295  36.0  \n1     2023-05-04 15:40:20    351  36.0  \n2     2023-05-04 15:48:25    352  40.0  \n3     2023-05-05 09:13:29    366  42.0  \n4     2023-05-05 09:19:05    368  57.0  \n...                   ...    ...   ...  \n2109  2024-08-01 10:26:46  25845  59.0  \n2110  2024-08-01 12:51:45  25906  52.0  \n2111  2024-08-02 08:33:15  25988  47.0  \n2112  2024-08-02 08:54:16  25999  37.0  \n2113  2024-08-02 11:23:20  26073  39.0  \n\n[2114 rows x 46 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ScoredAppID</th>\n      <th>CustomerID</th>\n      <th>frequency</th>\n      <th>avg_amountReq</th>\n      <th>med_amountReq</th>\n      <th>std_amountReq</th>\n      <th>Yeardiff_max</th>\n      <th>Yeardiff_min</th>\n      <th>Yeardiff_mean</th>\n      <th>Yeardiff_median</th>\n      <th>Monthdiff_max</th>\n      <th>Monthdiff_min</th>\n      <th>Monthdiff_mean</th>\n      <th>Monthdiff_median</th>\n      <th>Weekdiff_max</th>\n      <th>Weekdiff_min</th>\n      <th>Weekdiff_mean</th>\n      <th>Weekdiff_median</th>\n      <th>Daydiff_max</th>\n      <th>Daydiff_min</th>\n      <th>Daydiff_mean</th>\n      <th>Daydiff_median</th>\n      <th>have_valid_phone</th>\n      <th>times_valid_phone</th>\n      <th>total_phone_enter</th>\n      <th>correct_phone_rate</th>\n      <th>num_unique_valid_phone</th>\n      <th>Loanspaidoff_count</th>\n      <th>Incollection_count</th>\n      <th>Loanspaidoff_count_in30days</th>\n      <th>Incollection_count_in30days</th>\n      <th>Loanspaidoff_rate</th>\n      <th>Fraudster_app_count</th>\n      <th>Fraudster_lender_count</th>\n      <th>Fraudster_app_count_in30days</th>\n      <th>Fraudster_lender_count_in30days</th>\n      <th>Refused_count</th>\n      <th>Refused_rate</th>\n      <th>Refused_count_within30days</th>\n      <th>Refused_rate_within30days</th>\n      <th>Refused_count_before30days</th>\n      <th>Refused_rate_before30days</th>\n      <th>FPDAA</th>\n      <th>ApplicationDate</th>\n      <th>AppID</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>295</td>\n      <td>233.0</td>\n      <td>100</td>\n      <td>475.617978</td>\n      <td>500.0</td>\n      <td>343.090881</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2.340000</td>\n      <td>2.0</td>\n      <td>7</td>\n      <td>-4</td>\n      <td>1.400000</td>\n      <td>0.0</td>\n      <td>32</td>\n      <td>-19</td>\n      <td>5.980000</td>\n      <td>2.0</td>\n      <td>1142</td>\n      <td>499</td>\n      <td>893.280000</td>\n      <td>926.0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>100</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>62</td>\n      <td>0.659574</td>\n      <td>2</td>\n      <td>1.000000</td>\n      <td>60</td>\n      <td>0.652174</td>\n      <td>0.0</td>\n      <td>2023-05-03 16:53:28</td>\n      <td>295</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>351</td>\n      <td>281.0</td>\n      <td>10</td>\n      <td>375.000000</td>\n      <td>400.0</td>\n      <td>116.069902</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2.200000</td>\n      <td>2.0</td>\n      <td>7</td>\n      <td>-4</td>\n      <td>2.300000</td>\n      <td>4.0</td>\n      <td>32</td>\n      <td>-18</td>\n      <td>11.000000</td>\n      <td>18.0</td>\n      <td>1247</td>\n      <td>590</td>\n      <td>878.300000</td>\n      <td>925.0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.222222</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.285714</td>\n      <td>0.0</td>\n      <td>2023-05-04 15:40:20</td>\n      <td>351</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>352</td>\n      <td>282.0</td>\n      <td>4</td>\n      <td>616.666667</td>\n      <td>600.0</td>\n      <td>125.830574</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3.500000</td>\n      <td>3.5</td>\n      <td>17</td>\n      <td>15</td>\n      <td>15.750000</td>\n      <td>15.5</td>\n      <td>485</td>\n      <td>469</td>\n      <td>473.750000</td>\n      <td>470.5</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.750000</td>\n      <td>3</td>\n      <td>0.750000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2023-05-04 15:48:25</td>\n      <td>352</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>366</td>\n      <td>295.0</td>\n      <td>5</td>\n      <td>510.000000</td>\n      <td>500.0</td>\n      <td>159.687194</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.200000</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>-4</td>\n      <td>2.800000</td>\n      <td>4.0</td>\n      <td>28</td>\n      <td>-15</td>\n      <td>13.200000</td>\n      <td>18.0</td>\n      <td>622</td>\n      <td>468</td>\n      <td>529.000000</td>\n      <td>505.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1.000000</td>\n      <td>2</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>2023-05-05 09:13:29</td>\n      <td>366</td>\n      <td>42.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>368</td>\n      <td>296.0</td>\n      <td>2</td>\n      <td>675.000000</td>\n      <td>675.0</td>\n      <td>106.066017</td>\n      <td>7</td>\n      <td>2</td>\n      <td>4.500000</td>\n      <td>4.5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>3.000000</td>\n      <td>3.0</td>\n      <td>21</td>\n      <td>3</td>\n      <td>12.000000</td>\n      <td>12.0</td>\n      <td>2577</td>\n      <td>876</td>\n      <td>1726.500000</td>\n      <td>1726.5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.500000</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>2023-05-05 09:19:05</td>\n      <td>368</td>\n      <td>57.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2109</th>\n      <td>25845</td>\n      <td>15881.0</td>\n      <td>26</td>\n      <td>1242.307692</td>\n      <td>1250.0</td>\n      <td>283.792991</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.192308</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>-4</td>\n      <td>1.500000</td>\n      <td>1.0</td>\n      <td>26</td>\n      <td>-17</td>\n      <td>6.230769</td>\n      <td>4.0</td>\n      <td>321</td>\n      <td>19</td>\n      <td>112.730769</td>\n      <td>96.5</td>\n      <td>1</td>\n      <td>26</td>\n      <td>26</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.999997</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.090909</td>\n      <td>1</td>\n      <td>0.111111</td>\n      <td>1</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>2024-08-01 10:26:46</td>\n      <td>25845</td>\n      <td>59.0</td>\n    </tr>\n    <tr>\n      <th>2110</th>\n      <td>25906</td>\n      <td>6726.0</td>\n      <td>2</td>\n      <td>500.000000</td>\n      <td>500.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>-2</td>\n      <td>3.500000</td>\n      <td>3.5</td>\n      <td>425</td>\n      <td>351</td>\n      <td>388.000000</td>\n      <td>388.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>2024-08-01 12:51:45</td>\n      <td>25906</td>\n      <td>52.0</td>\n    </tr>\n    <tr>\n      <th>2111</th>\n      <td>25988</td>\n      <td>15977.0</td>\n      <td>3</td>\n      <td>1250.000000</td>\n      <td>1250.0</td>\n      <td>250.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>-4</td>\n      <td>-1.333333</td>\n      <td>-1.0</td>\n      <td>6</td>\n      <td>-18</td>\n      <td>-5.000000</td>\n      <td>-3.0</td>\n      <td>405</td>\n      <td>236</td>\n      <td>327.333333</td>\n      <td>341.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.666667</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>2024-08-02 08:33:15</td>\n      <td>25988</td>\n      <td>47.0</td>\n    </tr>\n    <tr>\n      <th>2112</th>\n      <td>25999</td>\n      <td>15985.0</td>\n      <td>20</td>\n      <td>381.578947</td>\n      <td>400.0</td>\n      <td>98.897430</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.700000</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>-3</td>\n      <td>3.850000</td>\n      <td>5.0</td>\n      <td>32</td>\n      <td>-12</td>\n      <td>17.100000</td>\n      <td>23.0</td>\n      <td>544</td>\n      <td>26</td>\n      <td>373.950000</td>\n      <td>480.0</td>\n      <td>1</td>\n      <td>20</td>\n      <td>20</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.999998</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0.500000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>0.526316</td>\n      <td>0.0</td>\n      <td>2024-08-02 08:54:16</td>\n      <td>25999</td>\n      <td>37.0</td>\n    </tr>\n    <tr>\n      <th>2113</th>\n      <td>5494</td>\n      <td>3364.0</td>\n      <td>7</td>\n      <td>692.857143</td>\n      <td>500.0</td>\n      <td>501.189062</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.857143</td>\n      <td>2.0</td>\n      <td>6</td>\n      <td>-4</td>\n      <td>1.714286</td>\n      <td>4.0</td>\n      <td>25</td>\n      <td>-18</td>\n      <td>8.285714</td>\n      <td>19.0</td>\n      <td>962</td>\n      <td>494</td>\n      <td>732.857143</td>\n      <td>737.0</td>\n      <td>1</td>\n      <td>7</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.333333</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.400000</td>\n      <td>0.0</td>\n      <td>2024-08-02 11:23:20</td>\n      <td>26073</td>\n      <td>39.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2114 rows × 46 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1742564795734
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "      FPDAA\n0       0.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0\n...     ...\n2109    0.0\n2110    0.0\n2111    0.0\n2112    0.0\n2113    0.0\n\n[2114 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FPDAA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2109</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2110</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2111</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2112</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2113</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2114 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1742564806122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:    \n",
        "    del x['Unnamed: 0']\n",
        "except:\n",
        "    pass\n",
        "try:    \n",
        "    del y['Unnamed: 0']\n",
        "except:\n",
        "    pass"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1742564842183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(max_depth=3, random_state=321111)\n",
        "features_modeling = ['frequency', 'avg_amountReq', 'med_amountReq',\n",
        "       'std_amountReq', 'Yeardiff_max', 'Yeardiff_min', 'Yeardiff_mean',\n",
        "       'Yeardiff_median', 'Monthdiff_max', 'Monthdiff_min', 'Monthdiff_mean',\n",
        "       'Monthdiff_median', 'Weekdiff_max', 'Weekdiff_min', 'Weekdiff_mean',\n",
        "       'Weekdiff_median', 'Daydiff_max', 'Daydiff_min', 'Daydiff_median',\n",
        "       'Daydiff_mean', 'have_valid_phone', 'times_valid_phone',\n",
        "       'total_phone_enter', 'correct_phone_rate', 'num_unique_valid_phone',\n",
        "        'Loanspaidoff_count', 'Incollection_count',\n",
        "       'Loanspaidoff_count_in30days', 'Incollection_count_in30days',\n",
        "       'Loanspaidoff_rate', 'Fraudster_app_count', 'Fraudster_lender_count',\n",
        "       'Fraudster_app_count_in30days', 'Fraudster_lender_count_in30days',\n",
        "       'Refused_count', 'Refused_rate', 'Refused_count_within30days',\n",
        "       'Refused_rate_within30days', 'Refused_count_before30days',\n",
        "       'Refused_rate_before30days']\n",
        "clf.fit(x[features_modeling], y.FPDAA.values)\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "def score(val, pred):\n",
        "    fpr, tpr, thresholds = roc_curve(val, pred[:,1]) \n",
        "    roc_auc = auc(fpr, tpr) \n",
        "    return roc_auc\n",
        "pred_dt = clf.predict_proba(x[features_modeling])\n",
        "print(score(y.FPDAA, pred_dt))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "0.716976920766304\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1742564845732
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'2.1.4'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1742564865094
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# joblib.dump(clf,'Users/andrew/Loonie_V3_ND/ND_V3_Testbed_V15.pkl')\n",
        "joblib.dump(clf,'ND_V3_Testbed_V15.pkl')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "['ND_V3_Testbed_V15.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1742564867483
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "      FPDAA\n0       0.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0\n...     ...\n2109    0.0\n2110    0.0\n2111    0.0\n2112    0.0\n2113    0.0\n\n[2114 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FPDAA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2109</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2110</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2111</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2112</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2113</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2114 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1723662015747
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "import joblib\n",
        "import json\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "def ndmodeling(jsonstr, modelfilepath, datacleanfilepath):\n",
        " \n",
        "    logging.basicConfig(filename=\"NDModel_WarningErrorLog_2023.log\", level=logging.WARNING, \n",
        "            format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "    \n",
        "    stepname = '1 Loading Json'\n",
        "    \n",
        "    if True:\n",
        "        # Load JsonStr variable\n",
        "        nb_dict = json.loads(jsonstr)\n",
        "        if nb_dict['NDB']['results'] == []:\n",
        "            return \"{\\\"ModelScore\\\":999,\\\"NDBand\\\":\" + str(6)+\"}\"\n",
        "            # fake model result as 1 to have it pass matrix threshold - the value need to be adusted to correct value\n",
        "        jsonString = json.dumps(nb_dict['NDB']['results'])\n",
        "        df_ = pd.DataFrame(json.loads(jsonString))\n",
        "        df_['accountnumber'] = nb_dict['NDB']['accountnumber']\n",
        "        \n",
        "        # Data Cleaning pre feature engineering\n",
        "        stepname = 'Data Cleaning pre feature engineering'\n",
        "        df_['amount'] = df_['amount'].replace('', 0).astype(float)\n",
        "        df_['requestDate'] = pd.to_datetime(df_.requestDate)\n",
        "        df_['Yeardiff'] = df_.apply(lambda x: (date.today().year - x['requestDate'].date().year), axis=1)\n",
        "        df_['Monthdiff'] = df_.apply(lambda x: (date.today().month - x['requestDate'].date().month), axis=1)\n",
        "        df_['Weekdiff'] = df_.apply(lambda x: (date.today().isocalendar()[1] - x['requestDate'].isocalendar()[1]), axis=1)\n",
        "        df_['Daydiff'] = df_.apply(lambda x: (date.today() - x['requestDate'].date()).days, axis=1)\n",
        "        df_['phone1'] = df_['phone1'].fillna('')\n",
        "        df_['phone2'] = df_['phone2'].fillna('')\n",
        "\n",
        "        # Feature engineering / feature generation\n",
        "        stepname = '2 Feature Generation'\n",
        "        frequency = df_.groupby('accountnumber').size().reset_index()\n",
        "        frequency.columns = ['accountnumber','frequency']\n",
        "\n",
        "        Loan = df_.groupby('accountnumber')['amount'].agg(['mean','median','std'])\n",
        "        Loan.columns = ['avg_amountReq','med_amountReq','std_amountReq']\n",
        "        Loan = Loan.reset_index()\n",
        "\n",
        "        tc_date = df_.groupby('accountnumber')[['Yeardiff','Monthdiff','Weekdiff','Daydiff']].agg(['max','min','mean','median'])\n",
        "        tc_date.columns = ['Yeardiff_max','Yeardiff_min','Yeardiff_mean','Yeardiff_median',\n",
        "                          'Monthdiff_max','Monthdiff_min','Monthdiff_mean','Monthdiff_median',\n",
        "                          'Weekdiff_max','Weekdiff_min','Weekdiff_mean','Weekdiff_median',\n",
        "                          'Daydiff_max','Daydiff_min','Daydiff_mean','Daydiff_median']\n",
        "        tc_date = tc_date.reset_index()\n",
        "\n",
        "        df_['phone1'] = df_.phone1.astype(str).str.replace(r'[\\(\\)-]','', regex = True).str.replace(r'\\s','', regex = True)\n",
        "        df_['phone2'] = df_.phone2.astype(str).str.replace(r'[\\(\\)-]','', regex = True).str.replace(r'\\s','', regex = True)\n",
        "\n",
        "        df_['cust_cell_number'] = df_.phone1.str.extract('(\\d+)').astype(str)\n",
        "        df_['cust_phone_number'] = df_.phone2.str.extract('(\\d+)').astype(str)\n",
        "\n",
        "        df_['true_phone'] = df_.apply(lambda x: 0 if ((len(x['cust_phone_number']) != 10) & (len(x['cust_cell_number']) != 10)) else 1, axis=1)\n",
        "        df_['cust_cell_number'] = df_.phone1.apply(lambda x: 'nan' if len(x) != 10 else x)\n",
        "        df_['cust_phone_number'] = df_.phone2.apply(lambda x: 'nan' if len(x) != 10 else x)\n",
        "        df_['phone_cell'] = df_.apply(lambda x: 0 if x['cust_phone_number'] == x['cust_cell_number'] else 1, axis=1)\n",
        "\n",
        "        phone = df_.groupby('accountnumber')['true_phone'].agg(['max','sum','count'])\n",
        "        phone['correct_phone_rate'] = phone['sum']/phone['count']\n",
        "        phone.columns = ['have_valid_phone','times_valid_phone','total_phone_enter','correct_phone_rate']\n",
        "        phone = phone.reset_index()\n",
        "\n",
        "        phone_count = df_[(df_['true_phone'] == 1) & (df_['cust_cell_number'] != 'nan')]\n",
        "        phone_count = pd.DataFrame(phone_count.groupby('accountnumber')[['cust_phone_number', 'cust_cell_number']].apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
        "        phone_count.columns = ['phone_list']\n",
        "        phone_count['num_unique_valid_phone'] = phone_count.phone_list.apply(lambda x: len(x) if 'nan' not in x else len(x)-1)\n",
        "        phone_count = phone_count.reset_index()\n",
        "\n",
        "        phone_features = pd.merge(phone, phone_count[['accountnumber','num_unique_valid_phone']], on='accountnumber',how='left')\n",
        "        phone_features['num_unique_valid_phone'] = phone_features['num_unique_valid_phone'].fillna(0)\n",
        "\n",
        "        \n",
        "        df_['refused'] = (df_['status'] == 'refused').astype(int)\n",
        "        df_['fraudster'] = (df_['status'] == 'fraudster').astype(int)\n",
        "        df_['duplicates'] = (df_['status'] == 'duplicates').astype(int)\n",
        "        df_['in-collection'] = (df_['status'] =='in-collection').astype(int)\n",
        "        df_['loan-pay-in-full'] = (df_['status'] =='loan-pay-in-full').astype(int)\n",
        "        \n",
        "        ### Make sure you change it!!!\n",
        "        curdate = date.today() \n",
        "        curdate = df_['requestDate'].max().date() # remove it before deployment\n",
        "        df_['within_last_30day'] = df_.apply(lambda x: (curdate - x['requestDate'].date()).days<=30, axis=1)\n",
        "\n",
        "        loanspaidoff_count = df_.groupby('accountnumber').apply(lambda x: x['loan-pay-in-full'].sum()).reset_index()\n",
        "        incollection_count = df_.groupby('accountnumber').apply(lambda x: x['in-collection'].sum()).reset_index()\n",
        "        try:\n",
        "            loanspaidoff_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[x.within_last_30day==1]['loan-pay-in-full'].sum()).reset_index()\n",
        "            incollection_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[x.within_last_30day==1]['in-collection'].sum()).reset_index()\n",
        "        except:\n",
        "            loanspaidoff_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Loanspaidoff_count_in30days':[0]})\n",
        "            incollection_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Incollection_count_in30days':[0]})        \n",
        "        loanspaidoff_rate = df_.groupby('accountnumber').apply(lambda x: x['loan-pay-in-full'].sum() / (x['loan-pay-in-full'].sum() + x['in-collection'].sum() + 0.00001) ).reset_index()\n",
        "        loanspaidoff_count.columns = ['accountnumber', 'Loanspaidoff_count']\n",
        "        incollection_count.columns = ['accountnumber', 'Incollection_count']\n",
        "        loanspaidoff_count_in30days.columns = ['accountnumber', 'Loanspaidoff_count_in30days']\n",
        "        incollection_count_in30days.columns = ['accountnumber', 'Incollection_count_in30days']\n",
        "        loanspaidoff_rate.columns = ['accountnumber', 'Loanspaidoff_rate']\n",
        "\n",
        "        fraudster_app_count = df_.groupby('accountnumber').apply(lambda x: x['fraudster'].sum()).reset_index()\n",
        "        fraudster_lender_count = df_.groupby('accountnumber').apply(lambda x: x[x.fraudster==1]['lender'].nunique()).reset_index()\n",
        "        if len(df_[df_.within_last_30day==True])==0:\n",
        "            fraudster_app_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Fraudster_app_count_in30days':[0]})\n",
        "            fraudster_lender_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Fraudster_lender_count_in30days':[0]})\n",
        "        else:\n",
        "            fraudster_app_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[x.within_last_30day==1]['fraudster'].sum()).reset_index()\n",
        "            fraudster_lender_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[(x.within_last_30day==1) & (x.fraudster==1)]['lender'].nunique()).reset_index()\n",
        "\n",
        "        fraudster_app_count.columns = ['accountnumber', 'Fraudster_app_count']\n",
        "        fraudster_lender_count.columns = ['accountnumber', 'Fraudster_lender_count']\n",
        "        fraudster_app_count_in30days.columns = ['accountnumber', 'Fraudster_app_count_in30days']\n",
        "        fraudster_lender_count_in30days.columns = ['accountnumber', 'Fraudster_lender_count_in30days']\n",
        "\n",
        "        refused_count = df_.groupby('accountnumber').apply(lambda x: x['refused'].sum()).reset_index()\n",
        "        refused_rate = df_.groupby('accountnumber').apply(lambda x: x['refused'].sum() / (x['refused'].count() -  x['duplicates'].sum()) if (x['refused'].count() - x['duplicates'].sum()) != 0 else 0).reset_index()\n",
        "        refused_count.columns = ['accountnumber', 'Refused_count']\n",
        "        refused_rate.columns = ['accountnumber', 'Refused_rate']\n",
        "\n",
        "        if len(df_[df_.within_last_30day==1])==0:\n",
        "            refused_count_within30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_count_within30days':[0]})\n",
        "            refused_rate_within30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_rate_within30days':[0]})\n",
        "        else:\n",
        "            refused_count_within30day = df_[df_.within_last_30day == True].groupby('accountnumber').apply(lambda row: row['refused'].sum()).reset_index()\n",
        "            refused_rate_within30day = df_[df_.within_last_30day == True].groupby('accountnumber').apply(lambda row: row['refused'].sum() / (row['refused'].count() - row['duplicates'].sum()) if (row['refused'].count() - row['duplicates'].sum()) != 0 else 0).reset_index()\n",
        "        if len(df_[df_.within_last_30day==0])==0:\n",
        "            refused_count_before30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_count_before30days':[0]})\n",
        "            refused_rate_before30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_rate_before30days':[0]})\n",
        "        else:\n",
        "            refused_count_before30day = df_[df_.within_last_30day == False].groupby('accountnumber').apply(lambda row: row['refused'].sum()).reset_index()\n",
        "            refused_rate_before30day = df_[df_.within_last_30day == False].groupby('accountnumber').apply(lambda row: row['refused'].sum() / (row['refused'].count() - row['duplicates'].sum()) if (row['refused'].count() - row['duplicates'].sum()) != 0 else 0).reset_index()\n",
        "\n",
        "        try:\n",
        "            refused_count_within30day.columns = ['accountnumber', 'Refused_count_within30days']\n",
        "            refused_rate_within30day.columns = ['accountnumber', 'Refused_rate_within30days']\n",
        "        except:\n",
        "            refused_count_within30day = pd.DataFrame(refused_count_before30day.values,columns = ['accountnumber', 'Refused_count_within30days'])\n",
        "            refused_rate_within30day = pd.DataFrame(refused_rate_before30day.values,columns = ['accountnumber', 'Refused_rate_within30days'])\n",
        "        try:\n",
        "            refused_count_before30day.columns = ['accountnumber', 'Refused_count_before30days']\n",
        "            refused_rate_before30day.columns = ['accountnumber', 'Refused_rate_before30days']\n",
        "        except:\n",
        "            refused_count_before30day = pd.DataFrame(refused_count_within30day.values,columns = ['accountnumber', 'Refused_count_before30days'])\n",
        "            refused_rate_before30day = pd.DataFrame(refused_rate_within30day.values,columns = ['accountnumber', 'Refused_rate_before30days'])\n",
        "\n",
        "        status_summary = loanspaidoff_count\n",
        "        for subdf in [incollection_count,loanspaidoff_count_in30days,incollection_count_in30days,loanspaidoff_rate,\n",
        "            fraudster_app_count, fraudster_lender_count,fraudster_app_count_in30days,fraudster_lender_count_in30days,\n",
        "            refused_count, refused_rate, refused_count_within30day,refused_rate_within30day, \n",
        "            refused_count_before30day, refused_rate_before30day]:\n",
        "            status_summary = status_summary.merge(subdf, on ='accountnumber', how='left')\n",
        "        \n",
        "        \n",
        "        feature_df = frequency\n",
        "        for d in [Loan, tc_date, phone_features, status_summary]:\n",
        "             feature_df = pd.merge(feature_df, d, on='accountnumber', how='outer')\n",
        "\n",
        "\n",
        "        # ND Data Cleaning post feature engineering\n",
        "        stepname = '3 Data Cleaning Post Feature Gen'\n",
        "        value_to_fillnull = pd.read_csv(datacleanfilepath) # 'saved/dataclean_nb_fillna.csv'\n",
        "\n",
        "        cols = ['avg_amountReq', 'med_amountReq', 'std_amountReq','times_valid_phone', \n",
        "            'total_phone_enter', 'correct_phone_rate','num_unique_valid_phone',\n",
        "            'Yeardiff_max','Yeardiff_min', 'Yeardiff_mean', 'Yeardiff_median', \n",
        "            'Monthdiff_max','Monthdiff_min', 'Monthdiff_mean', 'Monthdiff_median', \n",
        "            'Weekdiff_max','Weekdiff_min', 'Weekdiff_mean', 'Weekdiff_median', \n",
        "            'Daydiff_max','Daydiff_min', 'Daydiff_mean', 'Daydiff_median']\n",
        "        feature_df[cols]  = feature_df[cols].fillna(value_to_fillnull.loc[0,cols])\n",
        "\n",
        "        # Model loading and scoring\n",
        "        stepname = '4 Model Loading and Scoring'\n",
        "\n",
        "        clf_nb = joblib.load(modelfilepath) #example: datacleanfilepath = \"saved/NegativeDB_model.pkl\"\n",
        "\n",
        "        features_nb = ['frequency', 'avg_amountReq', 'med_amountReq',\n",
        "       'std_amountReq', 'Yeardiff_max', 'Yeardiff_min', 'Yeardiff_mean',\n",
        "       'Yeardiff_median', 'Monthdiff_max', 'Monthdiff_min', 'Monthdiff_mean',\n",
        "       'Monthdiff_median', 'Weekdiff_max', 'Weekdiff_min', 'Weekdiff_mean',\n",
        "       'Weekdiff_median', 'Daydiff_max', 'Daydiff_min', 'Daydiff_median',\n",
        "       'Daydiff_mean', 'have_valid_phone', 'times_valid_phone',\n",
        "       'total_phone_enter', 'correct_phone_rate', 'num_unique_valid_phone',\n",
        "        'Loanspaidoff_count', 'Incollection_count',\n",
        "       'Loanspaidoff_count_in30days', 'Incollection_count_in30days',\n",
        "       'Loanspaidoff_rate', 'Fraudster_app_count', 'Fraudster_lender_count',\n",
        "       'Fraudster_app_count_in30days', 'Fraudster_lender_count_in30days',\n",
        "       'Refused_count', 'Refused_rate', 'Refused_count_within30days',\n",
        "       'Refused_rate_within30days', 'Refused_count_before30days',\n",
        "       'Refused_rate_before30days']\n",
        "        \n",
        "        \"\"\"\n",
        "         ['frequency', 'avg_amountReq', 'med_amountReq','std_amountReq', \n",
        "               'Yeardiff_max', 'Yeardiff_min', 'Yeardiff_mean', 'Yeardiff_median',\n",
        "               'Monthdiff_max', 'Monthdiff_min', 'Monthdiff_mean', 'Monthdiff_median',\n",
        "               'Weekdiff_max', 'Weekdiff_min', 'Weekdiff_mean', 'Weekdiff_median',\n",
        "               'Daydiff_max', 'Daydiff_min', 'Daydiff_mean', 'Daydiff_median',\n",
        "               'have_valid_phone', 'times_valid_phone', 'total_phone_enter',\n",
        "               'correct_phone_rate', 'num_unique_valid_phone',\n",
        "               'Loanspaidoff_count', 'Incollection_count',\n",
        "               'Loanspaidoff_count_in30days', 'Incollection_count_in30days',\n",
        "               'Loanspaidoff_rate', 'Fraudster_app_count', 'Fraudster_lender_count',\n",
        "               'Fraudster_app_count_in30days', 'Fraudster_lender_count_in30days',\n",
        "               'Refused_count', 'Refused_rate', 'Refused_count_within30days',\n",
        "               'Refused_rate_within30days', 'Refused_count_before30days',\n",
        "               'Refused_rate_before30days']\n",
        "\"\"\"\n",
        "\n",
        "              \n",
        "\n",
        "        # Output 1: Prediction of FPD First Attempt\n",
        "        feature_df['NDScore'] = 1000 - (clf_nb.predict_proba(feature_df[features_nb])[:,1]*1000).astype(int)\n",
        "        # Output 2: Model Band\n",
        "        feature_df['NDBand'] = np.where(feature_df['NDScore']<376, 1, \n",
        "                               np.where(feature_df['NDScore']<580,2,\n",
        "                               np.where(feature_df['NDScore']<688,3,\n",
        "                               np.where(feature_df['NDScore']<766,4,5))))\n",
        "                \n",
        "    if False:\n",
        "        try:\n",
        "            logging.exception('AccountNumber: ' + str(nb_dict['NDB']['accountnumber']) + '; ErrorInStep: ' + stepname )\n",
        "        except:\n",
        "            logging.exception('AccountNumber: ' + 'Not Available' + '; ErrorInStep: ' + stepname )\n",
        "        finally:\n",
        "            return \"{\\\"ModelScore\\\":\"+str(0)+ \",\\\"NDBand\\\":\" + str(0)+\"}\"\n",
        "\n",
        "    return \"{\\\"ModelScore\\\":\"+str(feature_df['NDScore'].values[0])+ \",\\\"NDBand\\\":\" + str(feature_df['NDBand'].values[0])+\"}\""
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1742564886414
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": " \u001b[0m\u001b[01;32mNDModel_WarningErrorLog_2023.log\u001b[0m*       \u001b[01;32mnd_input_data.csv\u001b[0m*\r\n \u001b[01;32mND_V3_Testbed_V15.pkl\u001b[0m*                  \u001b[01;32mtraininginputdata.csv\u001b[0m*\r\n\u001b[01;32m'NegativeDB_model_V3_Testbed (2).pkl'\u001b[0m*   \u001b[01;32mtrainingoutputdata.csv\u001b[0m*\r\n \u001b[01;32mdataclean_nb_fillna.csv\u001b[0m*                \u001b[01;32mv3.ipynb\u001b[0m*\r\n\u001b[01;32m'input for NegativeDBModelLP_v1.json'\u001b[0m*   \u001b[01;32mv3.ipynb.amltmp\u001b[0m*\r\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1742564889013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'input for NegativeDBModelLP_v1.json'\n",
        "\n",
        "with open(data, 'r') as json_file:\n",
        "    data = json_file.read()\n",
        "modelfilepath = \"ND_V3_Testbed_V15.pkl\"\n",
        "datafilepath = \"dataclean_nb_fillna.csv\"\n",
        "ndmodeling(data, modelfilepath, datafilepath)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'{\"ModelScore\":815,\"NDBand\":5}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1742564889670
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelfilepath = 'NegativeDB_model_V3_Testbed (2).pkl'\n",
        "clf = joblib.load(modelfilepath)\n",
        "\n",
        "clf.feature_names_in_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "array(['frequency', 'avg_amountReq', 'Daydiff_mean', 'have_valid_phone',\n       'times_valid_phone', 'total_phone_enter', 'correct_phone_rate',\n       'num_unique_valid_phone', 'Loanspaidoff_count',\n       'Incollection_count', 'Loanspaidoff_count_in30days',\n       'Incollection_count_in30days', 'Loanspaidoff_rate',\n       'Fraudster_app_count', 'Fraudster_lender_count',\n       'Fraudster_app_count_in30days', 'Fraudster_lender_count_in30days',\n       'Refused_count', 'Refused_rate', 'Refused_count_within30days',\n       'Refused_rate_within30days', 'Refused_count_before30days',\n       'Refused_rate_before30days'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1742564892224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# where to the path: f = open(jsonfilepath)  example:  jsonfilepath = \"Data/creditbooksampleJSON.json\"    \n",
        "# where to replace the path: clf_nb = joblib.load(modelfilepath)   example: modelfilepath = \"saved/NegativeDB_model.pkl\"\n",
        "# where to replace the path: value_to_fillnull = pd.read_csv(datacleanfilepath)  example: datacleanfilepath = 'saved/dataclean_nb_fillna.csv'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "def ndmodeling(jsonbody, modelfilepath, datacleanfilepath):\n",
        " \n",
        "    stepname = '1 Loading Json'\n",
        "    \n",
        "    try:\n",
        "        if type(jsonbody) == str:\n",
        "            # print(\"Loading Json as string.\")\n",
        "            nb_dict = json.loads(jsonbody)\n",
        "        else:\n",
        "            # print(\"Json already in dict form\")\n",
        "            nb_dict = jsonbody\n",
        "        if nb_dict['NDB']['results'] == []:\n",
        "            return \"{\\\"ModelScore\\\":999,\\\"NDBand\\\":\" + str(6)+\"}\"\n",
        "            # fake model result as 1 to have it pass matrix threshold - the value need to be adusted to correct value\n",
        "        jsonString = json.dumps(nb_dict['NDB']['results'])\n",
        "        df_ = pd.DataFrame(json.loads(jsonString))\n",
        "        df_['accountnumber'] = nb_dict['NDB']['accountnumber']\n",
        "        \n",
        "        # Data Cleaning pre feature engineering\n",
        "        stepname = 'Data Cleaning pre feature engineering'\n",
        "        df_['amount'] = df_['amount'].replace('', 0).astype(float)\n",
        "        df_['requestDate'] = pd.to_datetime(df_.requestDate)\n",
        "        df_['Yeardiff'] = df_.apply(lambda x: (date.today().year - x['requestDate'].date().year), axis=1)\n",
        "        df_['Monthdiff'] = df_.apply(lambda x: (date.today().month - x['requestDate'].date().month), axis=1)\n",
        "        df_['Weekdiff'] = df_.apply(lambda x: (date.today().isocalendar()[1] - x['requestDate'].isocalendar()[1]), axis=1)\n",
        "        df_['Daydiff'] = df_.apply(lambda x: (date.today() - x['requestDate'].date()).days, axis=1)\n",
        "        df_['phone1'] = df_['phone1'].fillna('')\n",
        "        df_['phone2'] = df_['phone2'].fillna('')\n",
        "\n",
        "        # Feature engineering / feature generation\n",
        "        stepname = '2 Feature Generation'\n",
        "        frequency = df_.groupby('accountnumber').size().reset_index()\n",
        "        frequency.columns = ['accountnumber','frequency']\n",
        "\n",
        "        Loan = df_.groupby('accountnumber')['amount'].agg(['mean','median','std'])\n",
        "        Loan.columns = ['avg_amountReq','med_amountReq','std_amountReq']\n",
        "        Loan = Loan.reset_index()\n",
        "\n",
        "        tc_date = df_.groupby('accountnumber')[['Yeardiff','Monthdiff','Weekdiff','Daydiff']].agg(['max','min','mean','median'])\n",
        "        tc_date.columns = ['Yeardiff_max','Yeardiff_min','Yeardiff_mean','Yeardiff_median',\n",
        "                          'Monthdiff_max','Monthdiff_min','Monthdiff_mean','Monthdiff_median',\n",
        "                          'Weekdiff_max','Weekdiff_min','Weekdiff_mean','Weekdiff_median',\n",
        "                          'Daydiff_max','Daydiff_min','Daydiff_mean','Daydiff_median']\n",
        "        tc_date = tc_date.reset_index()\n",
        "\n",
        "        df_['phone1'] = df_.phone1.astype(str).str.replace(r'[\\(\\)-]','', regex = True).str.replace(r'\\s','', regex = True)\n",
        "        df_['phone2'] = df_.phone2.astype(str).str.replace(r'[\\(\\)-]','', regex = True).str.replace(r'\\s','', regex = True)\n",
        "\n",
        "        df_['cust_cell_number'] = df_.phone1.str.extract('(\\d+)').astype(str)\n",
        "        df_['cust_phone_number'] = df_.phone2.str.extract('(\\d+)').astype(str)\n",
        "\n",
        "        df_['true_phone'] = df_.apply(lambda x: 0 if ((len(x['cust_phone_number']) != 10) & (len(x['cust_cell_number']) != 10)) else 1, axis=1)\n",
        "        df_['cust_cell_number'] = df_.phone1.apply(lambda x: 'nan' if len(x) != 10 else x)\n",
        "        df_['cust_phone_number'] = df_.phone2.apply(lambda x: 'nan' if len(x) != 10 else x)\n",
        "        df_['phone_cell'] = df_.apply(lambda x: 0 if x['cust_phone_number'] == x['cust_cell_number'] else 1, axis=1)\n",
        "\n",
        "        phone = df_.groupby('accountnumber')['true_phone'].agg(['max','sum','count'])\n",
        "        phone['correct_phone_rate'] = phone['sum']/phone['count']\n",
        "        phone.columns = ['have_valid_phone','times_valid_phone','total_phone_enter','correct_phone_rate']\n",
        "        phone = phone.reset_index()\n",
        "\n",
        "        phone_count = df_[(df_['true_phone'] == 1) & (df_['cust_cell_number'] != 'nan')]\n",
        "        phone_count = pd.DataFrame(phone_count.groupby('accountnumber')[['cust_phone_number', 'cust_cell_number']].apply(lambda x: pd.unique(x.values.ravel()).tolist()))\n",
        "        phone_count.columns = ['phone_list']\n",
        "        phone_count['num_unique_valid_phone'] = phone_count.phone_list.apply(lambda x: len(x) if 'nan' not in x else len(x)-1)\n",
        "        phone_count = phone_count.reset_index()\n",
        "\n",
        "        phone_features = pd.merge(phone, phone_count[['accountnumber','num_unique_valid_phone']], on='accountnumber',how='left')\n",
        "        phone_features['num_unique_valid_phone'] = phone_features['num_unique_valid_phone'].fillna(0)\n",
        "\n",
        "        \n",
        "        df_['refused'] = (df_['status'] == 'refused').astype(int)\n",
        "        df_['fraudster'] = (df_['status'] == 'fraudster').astype(int)\n",
        "        df_['duplicates'] = (df_['status'] == 'duplicates').astype(int)\n",
        "        df_['in-collection'] = (df_['status'] =='in-collection').astype(int)\n",
        "        df_['loan-pay-in-full'] = (df_['status'] =='loan-pay-in-full').astype(int)\n",
        "        \n",
        "        ### Make sure you change it!!!\n",
        "        curdate = date.today() \n",
        "        curdate = df_['requestDate'].max().date() # remove it before deployment\n",
        "        df_['within_last_30day'] = df_.apply(lambda x: (curdate - x['requestDate'].date()).days<=30, axis=1)\n",
        "\n",
        "        loanspaidoff_count = df_.groupby('accountnumber').apply(lambda x: x['loan-pay-in-full'].sum()).reset_index()\n",
        "        incollection_count = df_.groupby('accountnumber').apply(lambda x: x['in-collection'].sum()).reset_index()\n",
        "        try:\n",
        "            loanspaidoff_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[x.within_last_30day==1]['loan-pay-in-full'].sum()).reset_index()\n",
        "            incollection_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[x.within_last_30day==1]['in-collection'].sum()).reset_index()\n",
        "        except:\n",
        "            loanspaidoff_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Loanspaidoff_count_in30days':[0]})\n",
        "            incollection_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Incollection_count_in30days':[0]})        \n",
        "        loanspaidoff_rate = df_.groupby('accountnumber').apply(lambda x: x['loan-pay-in-full'].sum() / (x['loan-pay-in-full'].sum() + x['in-collection'].sum() + 0.00001) ).reset_index()\n",
        "        loanspaidoff_count.columns = ['accountnumber', 'Loanspaidoff_count']\n",
        "        incollection_count.columns = ['accountnumber', 'Incollection_count']\n",
        "        loanspaidoff_count_in30days.columns = ['accountnumber', 'Loanspaidoff_count_in30days']\n",
        "        incollection_count_in30days.columns = ['accountnumber', 'Incollection_count_in30days']\n",
        "        loanspaidoff_rate.columns = ['accountnumber', 'Loanspaidoff_rate']\n",
        "\n",
        "        fraudster_app_count = df_.groupby('accountnumber').apply(lambda x: x['fraudster'].sum()).reset_index()\n",
        "        fraudster_lender_count = df_.groupby('accountnumber').apply(lambda x: x[x.fraudster==1]['lender'].nunique()).reset_index()\n",
        "        if len(df_[df_.within_last_30day==True])==0:\n",
        "            fraudster_app_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Fraudster_app_count_in30days':[0]})\n",
        "            fraudster_lender_count_in30days = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Fraudster_lender_count_in30days':[0]})\n",
        "        else:\n",
        "            fraudster_app_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[x.within_last_30day==1]['fraudster'].sum()).reset_index()\n",
        "            fraudster_lender_count_in30days = df_.groupby('accountnumber').apply(lambda x: x[(x.within_last_30day==1) & (x.fraudster==1)]['lender'].nunique()).reset_index()\n",
        "\n",
        "        fraudster_app_count.columns = ['accountnumber', 'Fraudster_app_count']\n",
        "        fraudster_lender_count.columns = ['accountnumber', 'Fraudster_lender_count']\n",
        "        fraudster_app_count_in30days.columns = ['accountnumber', 'Fraudster_app_count_in30days']\n",
        "        fraudster_lender_count_in30days.columns = ['accountnumber', 'Fraudster_lender_count_in30days']\n",
        "\n",
        "        refused_count = df_.groupby('accountnumber').apply(lambda x: x['refused'].sum()).reset_index()\n",
        "        refused_rate = df_.groupby('accountnumber').apply(lambda x: x['refused'].sum() / (x['refused'].count() -  x['duplicates'].sum()) if (x['refused'].count() - x['duplicates'].sum()) != 0 else 0).reset_index()\n",
        "        refused_count.columns = ['accountnumber', 'Refused_count']\n",
        "        refused_rate.columns = ['accountnumber', 'Refused_rate']\n",
        "\n",
        "        if len(df_[df_.within_last_30day==1])==0:\n",
        "            refused_count_within30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_count_within30days':[0]})\n",
        "            refused_rate_within30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_rate_within30days':[0]})\n",
        "        else:\n",
        "            refused_count_within30day = df_[df_.within_last_30day == True].groupby('accountnumber').apply(lambda row: row['refused'].sum()).reset_index()\n",
        "            refused_rate_within30day = df_[df_.within_last_30day == True].groupby('accountnumber').apply(lambda row: row['refused'].sum() / (row['refused'].count() - row['duplicates'].sum()) if (row['refused'].count() - row['duplicates'].sum()) != 0 else 0).reset_index()\n",
        "        if len(df_[df_.within_last_30day==0])==0:\n",
        "            refused_count_before30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_count_before30days':[0]})\n",
        "            refused_rate_before30day = pd.DataFrame({'accountnumber':[nb_dict['NDB']['accountnumber']],'Refused_rate_before30days':[0]})\n",
        "        else:\n",
        "            refused_count_before30day = df_[df_.within_last_30day == False].groupby('accountnumber').apply(lambda row: row['refused'].sum()).reset_index()\n",
        "            refused_rate_before30day = df_[df_.within_last_30day == False].groupby('accountnumber').apply(lambda row: row['refused'].sum() / (row['refused'].count() - row['duplicates'].sum()) if (row['refused'].count() - row['duplicates'].sum()) != 0 else 0).reset_index()\n",
        "\n",
        "        try:\n",
        "            refused_count_within30day.columns = ['accountnumber', 'Refused_count_within30days']\n",
        "            refused_rate_within30day.columns = ['accountnumber', 'Refused_rate_within30days']\n",
        "        except:\n",
        "            refused_count_within30day = pd.DataFrame(refused_count_before30day.values,columns = ['accountnumber', 'Refused_count_within30days'])\n",
        "            refused_rate_within30day = pd.DataFrame(refused_rate_before30day.values,columns = ['accountnumber', 'Refused_rate_within30days'])\n",
        "        try:\n",
        "            refused_count_before30day.columns = ['accountnumber', 'Refused_count_before30days']\n",
        "            refused_rate_before30day.columns = ['accountnumber', 'Refused_rate_before30days']\n",
        "        except:\n",
        "            refused_count_before30day = pd.DataFrame(refused_count_within30day.values,columns = ['accountnumber', 'Refused_count_before30days'])\n",
        "            refused_rate_before30day = pd.DataFrame(refused_rate_within30day.values,columns = ['accountnumber', 'Refused_rate_before30days'])\n",
        "\n",
        "        status_summary = loanspaidoff_count\n",
        "        for subdf in [incollection_count,loanspaidoff_count_in30days,incollection_count_in30days,loanspaidoff_rate,\n",
        "            fraudster_app_count, fraudster_lender_count,fraudster_app_count_in30days,fraudster_lender_count_in30days,\n",
        "            refused_count, refused_rate, refused_count_within30day,refused_rate_within30day, \n",
        "            refused_count_before30day, refused_rate_before30day]:\n",
        "            status_summary = status_summary.merge(subdf, on ='accountnumber', how='left')\n",
        "        \n",
        "        \n",
        "        feature_df = frequency\n",
        "        for d in [Loan, tc_date, phone_features, status_summary]:\n",
        "             feature_df = pd.merge(feature_df, d, on='accountnumber', how='outer')\n",
        "\n",
        "\n",
        "        # ND Data Cleaning post feature engineering\n",
        "        stepname = '3 Data Cleaning Post Feature Gen'\n",
        "        value_to_fillnull = pd.read_csv(datacleanfilepath) # 'saved/dataclean_nb_fillna.csv'\n",
        "\n",
        "        cols = ['avg_amountReq', 'med_amountReq', 'std_amountReq','times_valid_phone', \n",
        "            'total_phone_enter', 'correct_phone_rate','num_unique_valid_phone',\n",
        "            'Yeardiff_max','Yeardiff_min', 'Yeardiff_mean', 'Yeardiff_median', \n",
        "            'Monthdiff_max','Monthdiff_min', 'Monthdiff_mean', 'Monthdiff_median', \n",
        "            'Weekdiff_max','Weekdiff_min', 'Weekdiff_mean', 'Weekdiff_median', \n",
        "            'Daydiff_max','Daydiff_min', 'Daydiff_mean', 'Daydiff_median']\n",
        "        feature_df[cols]  = feature_df[cols].fillna(value_to_fillnull.loc[0,cols])\n",
        "\n",
        "        # Model loading and scoring\n",
        "        stepname = '4 Model Loading and Scoring'\n",
        "\n",
        "        clf_nb = joblib.load(modelfilepath) #example: datacleanfilepath = \"saved/NegativeDB_model.pkl\"\n",
        "\n",
        "        features_nb = ['frequency', 'avg_amountReq', 'med_amountReq',\n",
        "                        'std_amountReq', 'Yeardiff_max', 'Yeardiff_min', 'Yeardiff_mean',\n",
        "                        'Yeardiff_median', 'Monthdiff_max', 'Monthdiff_min', 'Monthdiff_mean',\n",
        "                        'Monthdiff_median', 'Weekdiff_max', 'Weekdiff_min', 'Weekdiff_mean',\n",
        "                        'Weekdiff_median', 'Daydiff_max', 'Daydiff_min', 'Daydiff_median',\n",
        "                        'Daydiff_mean', 'have_valid_phone', 'times_valid_phone',\n",
        "                        'total_phone_enter', 'correct_phone_rate', 'num_unique_valid_phone',\n",
        "                        'Loanspaidoff_count', 'Incollection_count',\n",
        "                        'Loanspaidoff_count_in30days', 'Incollection_count_in30days',\n",
        "                        'Loanspaidoff_rate', 'Fraudster_app_count', 'Fraudster_lender_count',\n",
        "                        'Fraudster_app_count_in30days', 'Fraudster_lender_count_in30days',\n",
        "                        'Refused_count', 'Refused_rate', 'Refused_count_within30days',\n",
        "                        'Refused_rate_within30days', 'Refused_count_before30days',\n",
        "                        'Refused_rate_before30days']\n",
        "\n",
        "        # Output 1: Prediction of FPD First Attempt\n",
        "        feature_df['NDScore'] = 1000 - (clf_nb.predict_proba(feature_df[features_nb])[:,1]*1000).astype(int)\n",
        "        # Output 2: Model Band\n",
        "        feature_df['NDBand'] = np.where(feature_df['NDScore']<376, 1, \n",
        "                               np.where(feature_df['NDScore']<580,2,\n",
        "                               np.where(feature_df['NDScore']<688,3,\n",
        "                               np.where(feature_df['NDScore']<766,4,5))))\n",
        "                \n",
        "    except:\n",
        "        try:\n",
        "            result = 'AccountNumber: ' + str(nb_dict['NDB']['accountnumber']) + '; ErrorInStep: ' + stepname\n",
        "        except:\n",
        "            result = 'AccountNumber: ' + 'Not Available' + '; ErrorInStep: ' + stepname\n",
        "        finally:\n",
        "            return result\n",
        "\n",
        "    return \"{\\\"ModelScore\\\":\"+str(feature_df['NDScore'].values[0])+ \",\\\"NDBand\\\":\" + str(feature_df['NDBand'].values[0])+\"}\"\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1742565475590
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'input for NegativeDBModelLP_v1.json'\n",
        "\n",
        "with open(data, 'r') as json_file:\n",
        "    data = json_file.read()\n",
        "modelfilepath = \"ND_V3_Testbed_V15.pkl\"\n",
        "datafilepath = \"dataclean_nb_fillna.csv\"\n",
        "ndmodeling(data, modelfilepath, datafilepath)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "'{\"ModelScore\":815,\"NDBand\":5}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1742565475826
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('TestData')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "['.amlignore',\n '.amlignore.amltmp',\n 'ND_56432.json',\n 'ND_56513.json',\n 'ND_56532.json',\n 'ND_56533.json',\n 'ND_56623.json',\n 'ND_56637.json',\n 'ND_56701.json',\n 'ND_56731.json',\n 'ND_56877.json',\n 'ND_56878.json']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1742565477119
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = ['ND_56432.json',\n",
        " 'ND_56513.json',\n",
        " 'ND_56532.json',\n",
        " 'ND_56533.json',\n",
        " 'ND_56623.json',\n",
        " 'ND_56637.json',\n",
        " 'ND_56701.json',\n",
        " 'ND_56731.json',\n",
        " 'ND_56877.json',\n",
        " 'ND_56878.json']\n",
        "\n",
        "\n",
        "for i in lst:\n",
        "    data = 'TestData/'+ str(i)\n",
        "    with open(data, 'r') as json_file:\n",
        "        data = json_file.read()\n",
        "    modelfilepath = \"ND_V3_Testbed_V15.pkl\"\n",
        "    datafilepath = \"dataclean_nb_fillna.csv\"\n",
        "    print(i,': ', ndmodeling(data, modelfilepath, datafilepath))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ND_56432.json :  {\"ModelScore\":686,\"NDBand\":3}\nND_56513.json :  {\"ModelScore\":780,\"NDBand\":5}\nND_56532.json :  {\"ModelScore\":726,\"NDBand\":4}\nND_56533.json :  {\"ModelScore\":869,\"NDBand\":5}\nND_56623.json :  {\"ModelScore\":778,\"NDBand\":5}\nND_56637.json :  {\"ModelScore\":813,\"NDBand\":5}\nND_56701.json :  {\"ModelScore\":700,\"NDBand\":4}\nND_56731.json :  {\"ModelScore\":737,\"NDBand\":4}\nND_56877.json :  {\"ModelScore\":843,\"NDBand\":5}\nND_56878.json :  {\"ModelScore\":789,\"NDBand\":5}\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1742565481948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "concordv16"
    },
    "kernelspec": {
      "name": "concordv16",
      "language": "python",
      "display_name": "CONCORDV16"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}